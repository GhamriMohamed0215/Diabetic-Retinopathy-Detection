{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JK8DoIWmDLT5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6OUn8CQwQ24",
        "outputId": "91920d0c-2f55-4c84-b261-1a032ef857de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/dtataset_5.zip -d /content/retinopathy"
      ],
      "metadata": {
        "id": "q75ArOKmOkdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "Zc7XbixkDxfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trdata = ImageDataGenerator()\n",
        "traindata = trdata.flow_from_directory( directory =\"/content/retinopathy/train\"#training dataset directory\n",
        ",target_size =(224 ,224) )\n",
        "tsdata = ImageDataGenerator()\n",
        "testdata = tsdata.flow_from_directory( directory =\"/content/retinopathy/val\"#validation dataset directory\n",
        "                                      , target_size =(224 ,224) )"
      ],
      "metadata": {
        "id": "X77hxbbEDvIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,BatchNormalization, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.regularizers import l2\n",
        "# Load pre-trained model\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "\n",
        "# Add classification layers on top of base model\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dropout(0.1),\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.1),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.1),\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.1),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.1),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.1),\n",
        "    Dense(1024, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.1),\n",
        "    Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(tf.keras.optimizers.legacy.Adam(lr=0.0001, decay=1e-9), loss='categorical_crossentropy', metrics=['accuracy','Precision','FalseNegatives','FalsePositives','TrueNegatives','TruePositives'])\n",
        "#model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# Define callbacks\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "earlystop = EarlyStopping(monitor='val_accuracy', min_delta=0.001, patience=10, verbose=1, mode='max', restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, verbose=1, mode='max', min_lr=0.0000001)\n",
        "#reduce_lr=ReduceLROnPlateau(monitor=\"val_accuracy\",mode=\"max\",factor=0.8,patience=5,verbose=1,min_delta=0.0000001)\n",
        "checkpoint = ModelCheckpoint(\"dens.h5\", monitor ='val_accuracy',\n",
        "verbose =1, save_best_only =True , save_weights_only =False , mode ='auto',period =1)\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    traindata,\n",
        "    epochs=50,\n",
        "    validation_data=testdata,\n",
        "    callbacks=[earlystop, lr_scheduler,checkpoint]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2107e41d-bba9-4fba-bb08-ad3558859bdf",
        "id": "3KMN09TYEAau"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 1.2369 - accuracy: 0.5664 - precision: 0.6638 - false_negatives: 1476.0000 - false_positives: 736.0000 - true_negatives: 10980.0000 - true_positives: 1453.0000\n",
            "Epoch 1: val_accuracy improved from -inf to 0.42033, saving model to dens.h5\n",
            "92/92 [==============================] - 52s 401ms/step - loss: 1.2369 - accuracy: 0.5664 - precision: 0.6638 - false_negatives: 1476.0000 - false_positives: 736.0000 - true_negatives: 10980.0000 - true_positives: 1453.0000 - val_loss: 1.4350 - val_accuracy: 0.4203 - val_precision: 1.0000 - val_false_negatives: 349.0000 - val_false_positives: 0.0000e+00 - val_true_negatives: 1456.0000 - val_true_positives: 15.0000 - lr: 1.0000e-04\n",
            "Epoch 2/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.4990 - accuracy: 0.8173 - precision: 0.8534 - false_negatives: 618.0000 - false_positives: 397.0000 - true_negatives: 11319.0000 - true_positives: 2311.0000\n",
            "Epoch 2: val_accuracy did not improve from 0.42033\n",
            "92/92 [==============================] - 33s 358ms/step - loss: 0.4990 - accuracy: 0.8173 - precision: 0.8534 - false_negatives: 618.0000 - false_positives: 397.0000 - true_negatives: 11319.0000 - true_positives: 2311.0000 - val_loss: 2.0985 - val_accuracy: 0.3104 - val_precision: 0.3261 - val_false_negatives: 259.0000 - val_false_positives: 217.0000 - val_true_negatives: 1239.0000 - val_true_positives: 105.0000 - lr: 1.0000e-04\n",
            "Epoch 3/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.3184 - accuracy: 0.8788 - precision: 0.8936 - false_negatives: 401.0000 - false_positives: 301.0000 - true_negatives: 11415.0000 - true_positives: 2528.0000\n",
            "Epoch 3: val_accuracy improved from 0.42033 to 0.72253, saving model to dens.h5\n",
            "92/92 [==============================] - 34s 371ms/step - loss: 0.3184 - accuracy: 0.8788 - precision: 0.8936 - false_negatives: 401.0000 - false_positives: 301.0000 - true_negatives: 11415.0000 - true_positives: 2528.0000 - val_loss: 1.4742 - val_accuracy: 0.7225 - val_precision: 0.7435 - val_false_negatives: 106.0000 - val_false_positives: 89.0000 - val_true_negatives: 1367.0000 - val_true_positives: 258.0000 - lr: 1.0000e-04\n",
            "Epoch 4/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.2525 - accuracy: 0.8986 - precision: 0.9090 - false_negatives: 321.0000 - false_positives: 261.0000 - true_negatives: 11455.0000 - true_positives: 2608.0000\n",
            "Epoch 4: val_accuracy improved from 0.72253 to 0.85165, saving model to dens.h5\n",
            "92/92 [==============================] - 34s 370ms/step - loss: 0.2525 - accuracy: 0.8986 - precision: 0.9090 - false_negatives: 321.0000 - false_positives: 261.0000 - true_negatives: 11455.0000 - true_positives: 2608.0000 - val_loss: 0.5745 - val_accuracy: 0.8516 - val_precision: 0.8528 - val_false_negatives: 57.0000 - val_false_positives: 53.0000 - val_true_negatives: 1403.0000 - val_true_positives: 307.0000 - lr: 1.0000e-04\n",
            "Epoch 5/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.1960 - accuracy: 0.9225 - precision: 0.9259 - false_negatives: 241.0000 - false_positives: 215.0000 - true_negatives: 11501.0000 - true_positives: 2688.0000\n",
            "Epoch 5: val_accuracy improved from 0.85165 to 0.92582, saving model to dens.h5\n",
            "92/92 [==============================] - 34s 371ms/step - loss: 0.1960 - accuracy: 0.9225 - precision: 0.9259 - false_negatives: 241.0000 - false_positives: 215.0000 - true_negatives: 11501.0000 - true_positives: 2688.0000 - val_loss: 0.1612 - val_accuracy: 0.9258 - val_precision: 0.9258 - val_false_negatives: 27.0000 - val_false_positives: 27.0000 - val_true_negatives: 1429.0000 - val_true_positives: 337.0000 - lr: 1.0000e-04\n",
            "Epoch 6/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.1728 - accuracy: 0.9249 - precision: 0.9293 - false_negatives: 235.0000 - false_positives: 205.0000 - true_negatives: 11511.0000 - true_positives: 2694.0000\n",
            "Epoch 6: val_accuracy did not improve from 0.92582\n",
            "92/92 [==============================] - 33s 356ms/step - loss: 0.1728 - accuracy: 0.9249 - precision: 0.9293 - false_negatives: 235.0000 - false_positives: 205.0000 - true_negatives: 11511.0000 - true_positives: 2694.0000 - val_loss: 0.1763 - val_accuracy: 0.9231 - val_precision: 0.9306 - val_false_negatives: 29.0000 - val_false_positives: 25.0000 - val_true_negatives: 1431.0000 - val_true_positives: 335.0000 - lr: 1.0000e-04\n",
            "Epoch 7/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.1665 - accuracy: 0.9283 - precision: 0.9306 - false_negatives: 219.0000 - false_positives: 202.0000 - true_negatives: 11514.0000 - true_positives: 2710.0000\n",
            "Epoch 7: val_accuracy improved from 0.92582 to 0.95604, saving model to dens.h5\n",
            "92/92 [==============================] - 36s 387ms/step - loss: 0.1665 - accuracy: 0.9283 - precision: 0.9306 - false_negatives: 219.0000 - false_positives: 202.0000 - true_negatives: 11514.0000 - true_positives: 2710.0000 - val_loss: 0.0879 - val_accuracy: 0.9560 - val_precision: 0.9559 - val_false_negatives: 17.0000 - val_false_positives: 16.0000 - val_true_negatives: 1440.0000 - val_true_positives: 347.0000 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.1449 - accuracy: 0.9396 - precision: 0.9420 - false_negatives: 184.0000 - false_positives: 169.0000 - true_negatives: 11547.0000 - true_positives: 2745.0000\n",
            "Epoch 8: val_accuracy did not improve from 0.95604\n",
            "92/92 [==============================] - 33s 355ms/step - loss: 0.1449 - accuracy: 0.9396 - precision: 0.9420 - false_negatives: 184.0000 - false_positives: 169.0000 - true_negatives: 11547.0000 - true_positives: 2745.0000 - val_loss: 0.0934 - val_accuracy: 0.9560 - val_precision: 0.9560 - val_false_negatives: 16.0000 - val_false_positives: 16.0000 - val_true_negatives: 1440.0000 - val_true_positives: 348.0000 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.1225 - accuracy: 0.9502 - precision: 0.9521 - false_negatives: 149.0000 - false_positives: 140.0000 - true_negatives: 11576.0000 - true_positives: 2780.0000\n",
            "Epoch 9: val_accuracy did not improve from 0.95604\n",
            "92/92 [==============================] - 34s 372ms/step - loss: 0.1225 - accuracy: 0.9502 - precision: 0.9521 - false_negatives: 149.0000 - false_positives: 140.0000 - true_negatives: 11576.0000 - true_positives: 2780.0000 - val_loss: 0.1049 - val_accuracy: 0.9533 - val_precision: 0.9533 - val_false_negatives: 17.0000 - val_false_positives: 17.0000 - val_true_negatives: 1439.0000 - val_true_positives: 347.0000 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.1268 - accuracy: 0.9464 - precision: 0.9476 - false_negatives: 161.0000 - false_positives: 153.0000 - true_negatives: 11563.0000 - true_positives: 2768.0000\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.95604\n",
            "92/92 [==============================] - 33s 357ms/step - loss: 0.1268 - accuracy: 0.9464 - precision: 0.9476 - false_negatives: 161.0000 - false_positives: 153.0000 - true_negatives: 11563.0000 - true_positives: 2768.0000 - val_loss: 0.0851 - val_accuracy: 0.9560 - val_precision: 0.9560 - val_false_negatives: 16.0000 - val_false_positives: 16.0000 - val_true_negatives: 1440.0000 - val_true_positives: 348.0000 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.1152 - accuracy: 0.9505 - precision: 0.9531 - false_negatives: 146.0000 - false_positives: 137.0000 - true_negatives: 11579.0000 - true_positives: 2783.0000\n",
            "Epoch 11: val_accuracy improved from 0.95604 to 0.95879, saving model to dens.h5\n",
            "92/92 [==============================] - 34s 371ms/step - loss: 0.1152 - accuracy: 0.9505 - precision: 0.9531 - false_negatives: 146.0000 - false_positives: 137.0000 - true_negatives: 11579.0000 - true_positives: 2783.0000 - val_loss: 0.0904 - val_accuracy: 0.9588 - val_precision: 0.9588 - val_false_negatives: 15.0000 - val_false_positives: 15.0000 - val_true_negatives: 1441.0000 - val_true_positives: 349.0000 - lr: 5.0000e-05\n",
            "Epoch 12/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.9597 - precision: 0.9613 - false_negatives: 120.0000 - false_positives: 113.0000 - true_negatives: 11603.0000 - true_positives: 2809.0000\n",
            "Epoch 12: val_accuracy improved from 0.95879 to 0.96978, saving model to dens.h5\n",
            "92/92 [==============================] - 34s 373ms/step - loss: 0.0958 - accuracy: 0.9597 - precision: 0.9613 - false_negatives: 120.0000 - false_positives: 113.0000 - true_negatives: 11603.0000 - true_positives: 2809.0000 - val_loss: 0.0788 - val_accuracy: 0.9698 - val_precision: 0.9698 - val_false_negatives: 11.0000 - val_false_positives: 11.0000 - val_true_negatives: 1445.0000 - val_true_positives: 353.0000 - lr: 5.0000e-05\n",
            "Epoch 13/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.9642 - precision: 0.9648 - false_negatives: 107.0000 - false_positives: 103.0000 - true_negatives: 11613.0000 - true_positives: 2822.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.96978\n",
            "92/92 [==============================] - 34s 373ms/step - loss: 0.0896 - accuracy: 0.9642 - precision: 0.9648 - false_negatives: 107.0000 - false_positives: 103.0000 - true_negatives: 11613.0000 - true_positives: 2822.0000 - val_loss: 0.0688 - val_accuracy: 0.9643 - val_precision: 0.9643 - val_false_negatives: 13.0000 - val_false_positives: 13.0000 - val_true_negatives: 1443.0000 - val_true_positives: 351.0000 - lr: 5.0000e-05\n",
            "Epoch 14/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 0.9734 - precision: 0.9747 - false_negatives: 79.0000 - false_positives: 74.0000 - true_negatives: 11642.0000 - true_positives: 2850.0000\n",
            "Epoch 14: val_accuracy did not improve from 0.96978\n",
            "92/92 [==============================] - 32s 353ms/step - loss: 0.0691 - accuracy: 0.9734 - precision: 0.9747 - false_negatives: 79.0000 - false_positives: 74.0000 - true_negatives: 11642.0000 - true_positives: 2850.0000 - val_loss: 0.0743 - val_accuracy: 0.9698 - val_precision: 0.9698 - val_false_negatives: 11.0000 - val_false_positives: 11.0000 - val_true_negatives: 1445.0000 - val_true_positives: 353.0000 - lr: 5.0000e-05\n",
            "Epoch 15/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0723 - accuracy: 0.9717 - precision: 0.9723 - false_negatives: 87.0000 - false_positives: 81.0000 - true_negatives: 11635.0000 - true_positives: 2842.0000\n",
            "Epoch 15: val_accuracy improved from 0.96978 to 0.97253, saving model to dens.h5\n",
            "92/92 [==============================] - 35s 377ms/step - loss: 0.0723 - accuracy: 0.9717 - precision: 0.9723 - false_negatives: 87.0000 - false_positives: 81.0000 - true_negatives: 11635.0000 - true_positives: 2842.0000 - val_loss: 0.0735 - val_accuracy: 0.9725 - val_precision: 0.9725 - val_false_negatives: 10.0000 - val_false_positives: 10.0000 - val_true_negatives: 1446.0000 - val_true_positives: 354.0000 - lr: 5.0000e-05\n",
            "Epoch 16/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.9744 - precision: 0.9761 - false_negatives: 76.0000 - false_positives: 70.0000 - true_negatives: 11646.0000 - true_positives: 2853.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.97253\n",
            "92/92 [==============================] - 33s 354ms/step - loss: 0.0706 - accuracy: 0.9744 - precision: 0.9761 - false_negatives: 76.0000 - false_positives: 70.0000 - true_negatives: 11646.0000 - true_positives: 2853.0000 - val_loss: 0.0903 - val_accuracy: 0.9725 - val_precision: 0.9725 - val_false_negatives: 10.0000 - val_false_positives: 10.0000 - val_true_negatives: 1446.0000 - val_true_positives: 354.0000 - lr: 5.0000e-05\n",
            "Epoch 17/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9826 - precision: 0.9833 - false_negatives: 52.0000 - false_positives: 49.0000 - true_negatives: 11667.0000 - true_positives: 2877.0000\n",
            "Epoch 17: val_accuracy did not improve from 0.97253\n",
            "92/92 [==============================] - 33s 356ms/step - loss: 0.0474 - accuracy: 0.9826 - precision: 0.9833 - false_negatives: 52.0000 - false_positives: 49.0000 - true_negatives: 11667.0000 - true_positives: 2877.0000 - val_loss: 0.0936 - val_accuracy: 0.9670 - val_precision: 0.9670 - val_false_negatives: 12.0000 - val_false_positives: 12.0000 - val_true_negatives: 1444.0000 - val_true_positives: 352.0000 - lr: 5.0000e-05\n",
            "Epoch 18/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9853 - precision: 0.9853 - false_negatives: 44.0000 - false_positives: 43.0000 - true_negatives: 11673.0000 - true_positives: 2885.0000\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.97253\n",
            "92/92 [==============================] - 33s 356ms/step - loss: 0.0388 - accuracy: 0.9853 - precision: 0.9853 - false_negatives: 44.0000 - false_positives: 43.0000 - true_negatives: 11673.0000 - true_positives: 2885.0000 - val_loss: 0.0880 - val_accuracy: 0.9698 - val_precision: 0.9698 - val_false_negatives: 11.0000 - val_false_positives: 11.0000 - val_true_negatives: 1445.0000 - val_true_positives: 353.0000 - lr: 5.0000e-05\n",
            "Epoch 19/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9874 - precision: 0.9884 - false_negatives: 37.0000 - false_positives: 34.0000 - true_negatives: 11682.0000 - true_positives: 2892.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.97253\n",
            "92/92 [==============================] - 34s 370ms/step - loss: 0.0342 - accuracy: 0.9874 - precision: 0.9884 - false_negatives: 37.0000 - false_positives: 34.0000 - true_negatives: 11682.0000 - true_positives: 2892.0000 - val_loss: 0.0937 - val_accuracy: 0.9670 - val_precision: 0.9670 - val_false_negatives: 12.0000 - val_false_positives: 12.0000 - val_true_negatives: 1444.0000 - val_true_positives: 352.0000 - lr: 2.5000e-05\n",
            "Epoch 20/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9921 - precision: 0.9921 - false_negatives: 24.0000 - false_positives: 23.0000 - true_negatives: 11693.0000 - true_positives: 2905.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.97253\n",
            "92/92 [==============================] - 33s 355ms/step - loss: 0.0235 - accuracy: 0.9921 - precision: 0.9921 - false_negatives: 24.0000 - false_positives: 23.0000 - true_negatives: 11693.0000 - true_positives: 2905.0000 - val_loss: 0.0856 - val_accuracy: 0.9698 - val_precision: 0.9698 - val_false_negatives: 11.0000 - val_false_positives: 11.0000 - val_true_negatives: 1445.0000 - val_true_positives: 353.0000 - lr: 2.5000e-05\n",
            "Epoch 21/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9935 - precision: 0.9935 - false_negatives: 19.0000 - false_positives: 19.0000 - true_negatives: 11697.0000 - true_positives: 2910.0000\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.97253\n",
            "92/92 [==============================] - 33s 353ms/step - loss: 0.0230 - accuracy: 0.9935 - precision: 0.9935 - false_negatives: 19.0000 - false_positives: 19.0000 - true_negatives: 11697.0000 - true_positives: 2910.0000 - val_loss: 0.0996 - val_accuracy: 0.9670 - val_precision: 0.9670 - val_false_negatives: 12.0000 - val_false_positives: 12.0000 - val_true_negatives: 1444.0000 - val_true_positives: 352.0000 - lr: 2.5000e-05\n",
            "Epoch 22/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9939 - precision: 0.9942 - false_negatives: 19.0000 - false_positives: 17.0000 - true_negatives: 11699.0000 - true_positives: 2910.0000\n",
            "Epoch 22: val_accuracy improved from 0.97253 to 0.97527, saving model to dens.h5\n",
            "92/92 [==============================] - 36s 386ms/step - loss: 0.0189 - accuracy: 0.9939 - precision: 0.9942 - false_negatives: 19.0000 - false_positives: 17.0000 - true_negatives: 11699.0000 - true_positives: 2910.0000 - val_loss: 0.0959 - val_accuracy: 0.9753 - val_precision: 0.9753 - val_false_negatives: 9.0000 - val_false_positives: 9.0000 - val_true_negatives: 1447.0000 - val_true_positives: 355.0000 - lr: 1.2500e-05\n",
            "Epoch 23/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 0.9915 - precision: 0.9915 - false_negatives: 26.0000 - false_positives: 25.0000 - true_negatives: 11691.0000 - true_positives: 2903.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.97527\n",
            "92/92 [==============================] - 33s 354ms/step - loss: 0.0282 - accuracy: 0.9915 - precision: 0.9915 - false_negatives: 26.0000 - false_positives: 25.0000 - true_negatives: 11691.0000 - true_positives: 2903.0000 - val_loss: 0.0991 - val_accuracy: 0.9725 - val_precision: 0.9725 - val_false_negatives: 10.0000 - val_false_positives: 10.0000 - val_true_negatives: 1446.0000 - val_true_positives: 354.0000 - lr: 1.2500e-05\n",
            "Epoch 24/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9884 - precision: 0.9887 - false_negatives: 35.0000 - false_positives: 33.0000 - true_negatives: 11683.0000 - true_positives: 2894.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.97527\n",
            "92/92 [==============================] - 33s 358ms/step - loss: 0.0345 - accuracy: 0.9884 - precision: 0.9887 - false_negatives: 35.0000 - false_positives: 33.0000 - true_negatives: 11683.0000 - true_positives: 2894.0000 - val_loss: 0.0999 - val_accuracy: 0.9670 - val_precision: 0.9670 - val_false_negatives: 12.0000 - val_false_positives: 12.0000 - val_true_negatives: 1444.0000 - val_true_positives: 352.0000 - lr: 1.2500e-05\n",
            "Epoch 25/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9952 - precision: 0.9956 - false_negatives: 14.0000 - false_positives: 13.0000 - true_negatives: 11703.0000 - true_positives: 2915.0000\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.97527\n",
            "92/92 [==============================] - 33s 358ms/step - loss: 0.0200 - accuracy: 0.9952 - precision: 0.9956 - false_negatives: 14.0000 - false_positives: 13.0000 - true_negatives: 11703.0000 - true_positives: 2915.0000 - val_loss: 0.1086 - val_accuracy: 0.9670 - val_precision: 0.9670 - val_false_negatives: 12.0000 - val_false_positives: 12.0000 - val_true_negatives: 1444.0000 - val_true_positives: 352.0000 - lr: 1.2500e-05\n",
            "Epoch 26/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9942 - precision: 0.9945 - false_negatives: 17.0000 - false_positives: 16.0000 - true_negatives: 11700.0000 - true_positives: 2912.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.97527\n",
            "92/92 [==============================] - 33s 354ms/step - loss: 0.0171 - accuracy: 0.9942 - precision: 0.9945 - false_negatives: 17.0000 - false_positives: 16.0000 - true_negatives: 11700.0000 - true_positives: 2912.0000 - val_loss: 0.1080 - val_accuracy: 0.9753 - val_precision: 0.9753 - val_false_negatives: 9.0000 - val_false_positives: 9.0000 - val_true_negatives: 1447.0000 - val_true_positives: 355.0000 - lr: 6.2500e-06\n",
            "Epoch 27/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9928 - precision: 0.9928 - false_negatives: 21.0000 - false_positives: 21.0000 - true_negatives: 11695.0000 - true_positives: 2908.0000\n",
            "Epoch 27: val_accuracy improved from 0.97527 to 0.97802, saving model to dens.h5\n",
            "92/92 [==============================] - 36s 391ms/step - loss: 0.0202 - accuracy: 0.9928 - precision: 0.9928 - false_negatives: 21.0000 - false_positives: 21.0000 - true_negatives: 11695.0000 - true_positives: 2908.0000 - val_loss: 0.1006 - val_accuracy: 0.9780 - val_precision: 0.9780 - val_false_negatives: 8.0000 - val_false_positives: 8.0000 - val_true_negatives: 1448.0000 - val_true_positives: 356.0000 - lr: 6.2500e-06\n",
            "Epoch 28/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9928 - precision: 0.9932 - false_negatives: 21.0000 - false_positives: 20.0000 - true_negatives: 11696.0000 - true_positives: 2908.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.97802\n",
            "92/92 [==============================] - 33s 354ms/step - loss: 0.0222 - accuracy: 0.9928 - precision: 0.9932 - false_negatives: 21.0000 - false_positives: 20.0000 - true_negatives: 11696.0000 - true_positives: 2908.0000 - val_loss: 0.1022 - val_accuracy: 0.9753 - val_precision: 0.9753 - val_false_negatives: 9.0000 - val_false_positives: 9.0000 - val_true_negatives: 1447.0000 - val_true_positives: 355.0000 - lr: 6.2500e-06\n",
            "Epoch 29/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9956 - precision: 0.9956 - false_negatives: 13.0000 - false_positives: 13.0000 - true_negatives: 11703.0000 - true_positives: 2916.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.97802\n",
            "92/92 [==============================] - 34s 370ms/step - loss: 0.0159 - accuracy: 0.9956 - precision: 0.9956 - false_negatives: 13.0000 - false_positives: 13.0000 - true_negatives: 11703.0000 - true_positives: 2916.0000 - val_loss: 0.1063 - val_accuracy: 0.9698 - val_precision: 0.9698 - val_false_negatives: 11.0000 - val_false_positives: 11.0000 - val_true_negatives: 1445.0000 - val_true_positives: 353.0000 - lr: 6.2500e-06\n",
            "Epoch 30/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9949 - precision: 0.9949 - false_negatives: 15.0000 - false_positives: 15.0000 - true_negatives: 11701.0000 - true_positives: 2914.0000\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.97802\n",
            "92/92 [==============================] - 33s 353ms/step - loss: 0.0177 - accuracy: 0.9949 - precision: 0.9949 - false_negatives: 15.0000 - false_positives: 15.0000 - true_negatives: 11701.0000 - true_positives: 2914.0000 - val_loss: 0.1120 - val_accuracy: 0.9670 - val_precision: 0.9670 - val_false_negatives: 12.0000 - val_false_positives: 12.0000 - val_true_negatives: 1444.0000 - val_true_positives: 352.0000 - lr: 6.2500e-06\n",
            "Epoch 31/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9928 - precision: 0.9932 - false_negatives: 21.0000 - false_positives: 20.0000 - true_negatives: 11696.0000 - true_positives: 2908.0000\n",
            "Epoch 31: val_accuracy did not improve from 0.97802\n",
            "92/92 [==============================] - 33s 358ms/step - loss: 0.0191 - accuracy: 0.9928 - precision: 0.9932 - false_negatives: 21.0000 - false_positives: 20.0000 - true_negatives: 11696.0000 - true_positives: 2908.0000 - val_loss: 0.1104 - val_accuracy: 0.9698 - val_precision: 0.9698 - val_false_negatives: 11.0000 - val_false_positives: 11.0000 - val_true_negatives: 1445.0000 - val_true_positives: 353.0000 - lr: 3.1250e-06\n",
            "Epoch 32/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9966 - precision: 0.9966 - false_negatives: 12.0000 - false_positives: 10.0000 - true_negatives: 11706.0000 - true_positives: 2917.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.97802\n",
            "92/92 [==============================] - 33s 354ms/step - loss: 0.0122 - accuracy: 0.9966 - precision: 0.9966 - false_negatives: 12.0000 - false_positives: 10.0000 - true_negatives: 11706.0000 - true_positives: 2917.0000 - val_loss: 0.1098 - val_accuracy: 0.9725 - val_precision: 0.9725 - val_false_negatives: 10.0000 - val_false_positives: 10.0000 - val_true_negatives: 1446.0000 - val_true_positives: 354.0000 - lr: 3.1250e-06\n",
            "Epoch 33/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9945 - precision: 0.9945 - false_negatives: 17.0000 - false_positives: 16.0000 - true_negatives: 11700.0000 - true_positives: 2912.0000\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.97802\n",
            "92/92 [==============================] - 33s 354ms/step - loss: 0.0174 - accuracy: 0.9945 - precision: 0.9945 - false_negatives: 17.0000 - false_positives: 16.0000 - true_negatives: 11700.0000 - true_positives: 2912.0000 - val_loss: 0.1055 - val_accuracy: 0.9753 - val_precision: 0.9753 - val_false_negatives: 9.0000 - val_false_positives: 9.0000 - val_true_negatives: 1447.0000 - val_true_positives: 355.0000 - lr: 3.1250e-06\n",
            "Epoch 34/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9966 - precision: 0.9966 - false_negatives: 10.0000 - false_positives: 10.0000 - true_negatives: 11706.0000 - true_positives: 2919.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.97802\n",
            "92/92 [==============================] - 33s 357ms/step - loss: 0.0123 - accuracy: 0.9966 - precision: 0.9966 - false_negatives: 10.0000 - false_positives: 10.0000 - true_negatives: 11706.0000 - true_positives: 2919.0000 - val_loss: 0.1062 - val_accuracy: 0.9753 - val_precision: 0.9753 - val_false_negatives: 9.0000 - val_false_positives: 9.0000 - val_true_negatives: 1447.0000 - val_true_positives: 355.0000 - lr: 1.5625e-06\n",
            "Epoch 35/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9956 - precision: 0.9956 - false_negatives: 14.0000 - false_positives: 13.0000 - true_negatives: 11703.0000 - true_positives: 2915.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.97802\n",
            "92/92 [==============================] - 33s 356ms/step - loss: 0.0130 - accuracy: 0.9956 - precision: 0.9956 - false_negatives: 14.0000 - false_positives: 13.0000 - true_negatives: 11703.0000 - true_positives: 2915.0000 - val_loss: 0.1067 - val_accuracy: 0.9753 - val_precision: 0.9753 - val_false_negatives: 9.0000 - val_false_positives: 9.0000 - val_true_negatives: 1447.0000 - val_true_positives: 355.0000 - lr: 1.5625e-06\n",
            "Epoch 36/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9928 - precision: 0.9928 - false_negatives: 22.0000 - false_positives: 21.0000 - true_negatives: 11695.0000 - true_positives: 2907.0000\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.97802\n",
            "92/92 [==============================] - 33s 355ms/step - loss: 0.0225 - accuracy: 0.9928 - precision: 0.9928 - false_negatives: 22.0000 - false_positives: 21.0000 - true_negatives: 11695.0000 - true_positives: 2907.0000 - val_loss: 0.1076 - val_accuracy: 0.9753 - val_precision: 0.9753 - val_false_negatives: 9.0000 - val_false_positives: 9.0000 - val_true_negatives: 1447.0000 - val_true_positives: 355.0000 - lr: 1.5625e-06\n",
            "Epoch 37/50\n",
            "92/92 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9942 - precision: 0.9942 - false_negatives: 17.0000 - false_positives: 17.0000 - true_negatives: 11699.0000 - true_positives: 2912.0000Restoring model weights from the end of the best epoch: 27.\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.97802\n",
            "92/92 [==============================] - 33s 356ms/step - loss: 0.0214 - accuracy: 0.9942 - precision: 0.9942 - false_negatives: 17.0000 - false_positives: 17.0000 - true_negatives: 11699.0000 - true_positives: 2912.0000 - val_loss: 0.1070 - val_accuracy: 0.9753 - val_precision: 0.9753 - val_false_negatives: 9.0000 - val_false_positives: 9.0000 - val_true_negatives: 1447.0000 - val_true_positives: 355.0000 - lr: 7.8125e-07\n",
            "Epoch 37: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apq6qqaeY_n4",
        "outputId": "d9c07fda-482d-4a04-b016-94d47a873db0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2848 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "tssdata = ImageDataGenerator()\n",
        "tst = tssdata.flow_from_directory( directory =\"/content/retinopathy/test\"\n",
        ",target_size =(224 ,224) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ5UXzMXJMJ0",
        "outputId": "fcbf5bb2-0ff2-4f17-d3fe-207c5f08236d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89/89 [==============================] - 9s 100ms/step - loss: 0.1678 - accuracy: 0.9705 - precision: 0.9705 - false_negatives: 84.0000 - false_positives: 84.0000 - true_negatives: 11308.0000 - true_positives: 2764.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.16777174174785614,\n",
              " 0.9705055952072144,\n",
              " 0.9705055952072144,\n",
              " 84.0,\n",
              " 84.0,\n",
              " 11308.0,\n",
              " 2764.0]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "model.evaluate(tst)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "#tst.reset()\n",
        "X_test, Y_test = next(tst)\n",
        "for i in tqdm.tqdm(range(int(tst.n/32))):\n",
        "  img, label = next(tst)\n",
        "  X_test = np.append(X_test, img, axis=0 )\n",
        "  Y_test = np.append(Y_test, label, axis=0)\n",
        "print(X_test.shape, Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZqJ1Cj_ITG9",
        "outputId": "b5f88254-a63d-46fb-c8fd-33ce92f1e39d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 89/89 [00:40<00:00,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2880, 224, 224, 3) (2880, 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "y_pred = np.argmax(predictions, axis=1)\n",
        "\n",
        "true_classes =  np.argmax(Y_test, axis=1)\n",
        "\n",
        "#class_labels = list(tst.class_indices.keys())\n",
        "\n",
        "#print(class_labels)\n",
        "\n",
        "print(confusion_matrix(true_classes, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg4-pY28Ewhy",
        "outputId": "18f83800-bc28-42a4-e33c-5aedc7669f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 10s 92ms/step\n",
            "[[840   0   0   0   0]\n",
            " [  0 688   0   0   0]\n",
            " [  0   0 460   0   0]\n",
            " [  0   0   0 323  24]\n",
            " [  0   0   0  61 484]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "CM=confusion_matrix(true_classes, y_pred)\n",
        "fig, ax = plot_confusion_matrix(conf_mat=CM,figsize=(5,5))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "GfQV1oJA4ZVm",
        "outputId": "46df7628-3b91-4978-f88b-cfe8adc337ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "def calculate_precision(cm, class_index):\n",
        "    # Extract the true positives and false positives for the specified class\n",
        "    tp = cm[class_index, class_index]\n",
        "    fp = sum(cm[:, class_index]) - tp\n",
        "\n",
        "    # Calculate precision\n",
        "    precision = tp / (tp + fp)\n",
        "    return precision\n",
        "\n",
        "def calculate_recall(cm, class_index):\n",
        "    # Extract the true positives and false negatives for the specified class\n",
        "    tp = cm[class_index, class_index]\n",
        "    fn = sum(cm[class_index, :]) - tp\n",
        "\n",
        "    # Calculate recall\n",
        "    recall = tp / (tp + fn)\n",
        "    return recall\n",
        "\n",
        "def calculate_f1_score(precision, recall):\n",
        "    # Calculate F1 score\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    return f1_score\n",
        "\n",
        "num_classes = cm.shape[0]  # Number of classes in your multiclassification problem\n",
        "\n",
        "# Calculate precision, recall, and F1 score for each class\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "for class_index in range(num_classes):\n",
        "    precision = calculate_precision(cm, class_index)\n",
        "    recall = calculate_recall(cm, class_index)\n",
        "    f1_score = calculate_f1_score(precision, recall)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1_score)\n",
        "\n",
        "# Print precision, recall, and F1 score for each class\n",
        "for class_index in range(num_classes):\n",
        "    print(f\"Metrics for class {class_index}:\")\n",
        "    print(f\"  Precision: {precisions[class_index]}\")\n",
        "    print(f\"  Recall: {recalls[class_index]}\")\n",
        "    print(f\"  F1 Score: {f1_scores[class_index]}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYbJDa96EyjV",
        "outputId": "d64d4d96-f37b-448c-e594-7b63a0fcce03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for class 0:\n",
            "  Precision: 1.0\n",
            "  Recall: 1.0\n",
            "  F1 Score: 1.0\n",
            "\n",
            "Metrics for class 1:\n",
            "  Precision: 1.0\n",
            "  Recall: 1.0\n",
            "  F1 Score: 1.0\n",
            "\n",
            "Metrics for class 2:\n",
            "  Precision: 1.0\n",
            "  Recall: 1.0\n",
            "  F1 Score: 1.0\n",
            "\n",
            "Metrics for class 3:\n",
            "  Precision: 0.8411458333333334\n",
            "  Recall: 0.930835734870317\n",
            "  F1 Score: 0.8837209302325582\n",
            "\n",
            "Metrics for class 4:\n",
            "  Precision: 0.952755905511811\n",
            "  Recall: 0.8880733944954129\n",
            "  F1 Score: 0.919278252611586\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming you have the true labels and predicted labels for your multiclassification model\n",
        "\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(true_labels, predicted_labels)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-wUAalpF-vz",
        "outputId": "9bb6ef0c-b4db-4828-ed65-4370a3914dca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       840\n",
            "           1       1.00      1.00      1.00       688\n",
            "           2       1.00      1.00      1.00       460\n",
            "           3       0.84      0.93      0.88       347\n",
            "           4       0.95      0.89      0.92       545\n",
            "\n",
            "    accuracy                           0.97      2880\n",
            "   macro avg       0.96      0.96      0.96      2880\n",
            "weighted avg       0.97      0.97      0.97      2880\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/Densenet-121_5_classes.h5\")"
      ],
      "metadata": {
        "id": "dsJj-vDudC6i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}